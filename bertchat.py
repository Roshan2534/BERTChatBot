# -*- coding: utf-8 -*-
"""BERTChat.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LEDp7LMLiUq05Y-sk0BpS5jmYxs1Vcny
"""

!pip install sentencepiece
!pip install tf-models-nightly
!pip install tf-nightly

import tensorflow as tf

import tensorflow_hub as hub
from official.nlp.bert.tokenization import FullTokenizer
from official.nlp.bert.input_pipeline import create_squad_dataset
from official.nlp.data.squad_lib import generate_tf_record_from_json_file
from official.nlp import optimization
from official.nlp.data.squad_lib import read_squad_examples
from official.nlp.data.squad_lib import FeatureWriter
from official.nlp.data.squad_lib import convert_examples_to_features
from official.nlp.data.squad_lib import write_predictions

import numpy as np
import math
import random
import time
import json
import collections
import os

from google.colab import drive

drive.mount("/content/drive")

input_meta_data = generate_tf_record_from_json_file(
    "/content/drive/MyDrive/BERT/ChatBot/train-v1.1.json",
    "/content/drive/MyDrive/BERT/ChatBot/vocab.txt",
    "/content/drive/MyDrive/BERT/ChatBot/train-v1.1.tf_record"
)

with tf.io.gfile.GFile("/content/drive/MyDrive/BERT/ChatBot/train_meta_data","w") as writer:
    writer.write(json.dumps(input_meta_data, indent=4)+"\n")

BATCH_SIZE = 4
train_dataset = create_squad_dataset("/content/drive/MyDrive/BERT/ChatBot/train-v1.1.tf_record",
                                     input_meta_data["max_seq_length"],
                                     BATCH_SIZE,
                                     is_training=True)

class BertSquadLayer(tf.keras.layers.Layer):

    def __init__(self):
        super(BertSquadLayer, self).__init__()
        self.final_dense = tf.keras.layers.Dense(
            units=2,
            kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02)
        )
    
    def call(self,inputs):
        logits = self.final_dense(inputs)

        logits = tf.transpose(logits, [2,0,1])
        unstacked_logits = tf.unstack(logits, axis=0)
        return unstacked_logits[0], unstacked_logits[1]

